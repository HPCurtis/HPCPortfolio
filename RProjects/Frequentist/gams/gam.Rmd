---
title: "Bike"
author: "Harrison Curtis"
date: "2023-09-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Import analysis and visualisation libraries
```{r, message=FALSE}
library('mgcv')
library('dplyr')
library('ggplot2')
library('gratia')
```
# Import, organsise and reduce dataset for Bike sharing data that is stored on github downloaded from the California Irvine Machine Learning repository. 

```{r}
d <- read.csv('https://raw.githubusercontent.com/BayesianModelingandComputationInPython/BookCode_Edition1/main/data/bikes_hour.csv')
d <- d[order(d[,'hour']),]

# Standardise data
d[, 'count'] <- scale(d[, 'count'])

# Take every 50th row value of the dateset
d <- d[seq(1, nrow(d), 50), ]
```


```{r}
# Visualise the normalised Bike count data
ggplot(data = d, aes(x = d[ ,'hour'], y = d[ , 'count'])) +
  geom_point(alpha=.3) + xlab('hour') + ylab('Normalised Count') +
  theme_bw()
```


```{r}
# Fit gam using MGCV package
M1 <- gam(count ~ s(hour), data = d, family = gaussian )
summary(M1)
```


```{r}
sm <- smooth_estimates(M1, smooth = "s(hour)")
# Plot the GAM model fit
sm %>%
  add_confint() %>%
  ggplot(aes(y = est, x = hour)) +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci),
              alpha = 0.2, fill = "forestgreen") +
  geom_line(colour = "forestgreen", linewidth = 1.5) + ylab('Partial effect') +
  geom_point(data = d, aes(x = d[ ,'hour'], y = d[ , 'count']),alpha=.3 ) + theme_bw()

```
