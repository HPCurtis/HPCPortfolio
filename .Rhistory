rnorm(100)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
library(rstan)
version
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
library(rstan)
install.packages("processx")
library(rstan)
example(stan_model, package = "rstan", run.dontrun = TRUE)
dotR <- file.path(Sys.getenv("HOME"), ".R")
if (!file.exists(dotR)) dir.create(dotR)
M <- file.path(dotR, "Makevars")
if (!file.exists(M)) file.create(M)
arch <- ifelse(R.version$arch == "aarch64", "arm64", "x86_64")
cat(paste("\nCXX14FLAGS += -O3 -mtune=native -arch", arch, "-ftemplate-depth-256"),
file = M, sep = "\n", append = FALSE)
install.packages('brms')
temp <- c(11.9,14.2,15.2,16.4,17.2,18.1,18.5,19.4,22.1,22.6,23.4,25.1)
units <- c(185L,215L,332L,325L,408L,421L,406L,412L,522L,445L,544L,614L)
log_units <- log(units)
n <- length(units)
market.size <- rep(800,n)
lin.mod <- brm(units ~ temp, family="gaussian")
library(brms)
lin.mod <- brm(units ~ temp, family="gaussian")
d <- data.frame(temp,units)
View(d)
lin.mod <- brm(units ~ temp, family="gaussian", data = d)
x <- 1
x <- 2
library(tidyverse)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy))
fliter(mpg, cyl = 8)
library(tidyverse)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy))
filter(mpg, cyl = 8)
library(tidyverse)
ggplot(data = mpg) +
geom_point(mapping = aes(x = displ, y = hwy))
filter(mpg, cyl == 8)
filter(diamond, carat > 3)
install.packages("nycflights13")
library(tidyverse)
ibrary(nycflights13)
library(nycflights13)
flights
filter(flights, day ==1)
filter(flights, month == 1, day == 1)
dataPHD <- read.csv2(file="https://raw.githubusercontent.com/LaurentSmeets/Tutorials/master/Blavaan/phd-delays.csv")
colnames(dataPHD) <- c("diff", "child", "sex","age","age2")
View(dataPHD)
describe(data(dataPHD))
library(psych)
install.packages("psych")
library(psych)
describe(data(dataPHD))
describe(dataPHD)
dataPHD %>%
ggplot(aes(x = age,
y = diff)) +
geom_point(position = "jitter",
alpha    = .6)+ #to add some random noise for plotting purposes
theme_minimal()+
geom_smooth(method = "lm",  # to add  the linear relationship
aes(color = "linear"),
se = FALSE) +
geom_smooth(method = "lm",
formula = y ~ x + I(x^2),# to add  the quadratic relationship
aes(color = "quadratic"),
se = FALSE) +
labs(title    = "Delay vs. age",
subtitle = "There seems to be some quadratic relationship",
x        = "Age",
y        = "Delay",
color    = "Type of relationship" ) +
theme(legend.position = "bottom")
library(lavaan)
install.packages("lavaan")
library(lavaan)
model.regression <- '#the regression model
diff ~ age + age2
#show that dependent variable has variance
diff ~~ diff
#we want to have an intercept
diff ~ 1'
summary(model.regression)
model.regression
summary(fit, fit.measures = TRUE, ci = TRUE, rsquare = TRUE)
fit <- lavaan(model = model.regression, data = dataPHD)
summary(fit, fit.measures = TRUE, ci = TRUE, rsquare = TRUE)
ibrary(tidyverse)
library(tidyverse)
library(rstan)
rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
asc70 <- read.csv('https://raw.githubusercontent.com/TinyvanBoekel/FRI/main/datafiles/asc_70_me.csv''' header=TRUE, sep=";")
asc70 <- read.csv('https://raw.githubusercontent.com/TinyvanBoekel/FRI/main/datafiles/asc_70_me.csv' header=TRUE, sep=";")
asc70 <- read.csv('https://raw.githubusercontent.com/TinyvanBoekel/FRI/main/datafiles/asc_70_me.csv', header=TRUE, sep=";")
asc70 <- rename(asc70, run=serial)
asc70$run <- as.factor(asc70$run)
asc_avg_norm <- read.csv(file=here("data", "asc_avg_norm.csv"), header=TRUE, sep=";")
asc70 <- rename(asc70, run=serial)
View(asc70)
asc70 <- rename(asc70, run='serial')
asc70 <- rename(asc70, 'run'='serial')
asc70 %>% rename('run'='serial')
asc70
asc70 %>% rename(run =serial)
asc70 %>% rename(serial =run)
asc70 %>% rename(serial =run)
asc70 %>% rename(serial =run)
asc70$run <- as.factor(asc70$run)
asc70$run <- as.factor(asc70$run)
asc70
asc_avg_norm <- read.csv(file=here('https://raw.githubusercontent.com/TinyvanBoekel/FRI/main/datafiles/asc_avg_norm.csv'), header=TRUE, sep=";")
asc_avg_norm <- read.csv(file = ('https://raw.githubusercontent.com/TinyvanBoekel/FRI/main/datafiles/asc_avg_norm.csv'), header=TRUE, sep=";")
library(brms)
# brms code for regression of averaged normalized concentration:
nlform<-bf(avg ~ exp(-kr*time),
kr~1, nl=TRUE)
nlprior<-c(prior(normal(0.5,0.3), nlpar="kr", lb=0),
prior(cauchy(0,10), class="sigma")
)
asc_avg_norm_bayes <- brm(formula=nlform, data=asc_avg_norm, family = gaussian(),
prior = nlprior, iter = 4000, warmup=2000,
control = list(adapt_delta = 0.99),
file=here("fits", "asc_avg_norm_bayes"))
asc_avg_norm_bayes <- brm(formula=nlform, data=asc_avg_norm, family = gaussian(),
prior = nlprior, iter = 4000, warmup=2000,
control = list(adapt_delta = 0.99))
stancode(asc_avg_norm_bayes)
View(asc_avg_norm)
View(asc_avg_norm_bayes)
standata(asc_avg_norm_bayes)
asc_avg_norm_bayes
nlform<-bf(conc ~ (c0^(1-nt)+(nt-1)*k*time)^(1/(1-nt)), c0~1, k~1, nt~1,nl=TRUE)
nlprior<-c(prior(normal(6,1), nlpar = "c0"),
prior(normal(0.3,0.3), nlpar="k"),
prior(normal(1,0.5), nlpar="nt"),
prior(cauchy(0,10), class="sigma")
)
asc_bayes_all <- brm(formula=nlform, data=asc70, family = gaussian(), prior = nlprior, warmup=3000, iter=6000, chains=4, control = list(adapt_delta = 0.999), file=here("fits","asc_bayes_all"))
nlform<-bf(conc ~ (c0^(1-nt)+(nt-1)*k*time)^(1/(1-nt)), c0~1, k~1, nt~1,nl=TRUE)
nlprior<-c(prior(normal(6,1), nlpar = "c0"),
prior(normal(0.3,0.3), nlpar="k"),
prior(normal(1,0.5), nlpar="nt"),
prior(cauchy(0,10), class="sigma")
)
asc_bayes_all <- brm(formula=nlform, data=asc70, family = gaussian(), prior = nlprior, warmup=3000, iter=6000, chains=4, control = list(adapt_delta = 0.999))
stancode(asc_bayes_all)
asc_bayes_all
nlform<-bf(conc ~ (c0^(1-nt)+(nt-1)*kr*time)^(1/(1-nt)),
c0 ~1+(1|ID|run),
nt~1+(1|ID|run),
kr ~ 1+(1|ID|run),
nl=TRUE)
nlprior<-c(prior(normal(6.0,0.5), nlpar = "c0", lb=0),
prior(normal(0.5,0.1), nlpar="kr", lb=0),
prior(normal(1,0.1), nlpar="nt", lb=0),
prior(cauchy(0,1), class="sigma"),
prior(cauchy(0,1), class="sd", nlpar="c0"),
prior(cauchy(0,1), class="sd", nlpar="nt"),
prior(cauchy(0,1), class="sd", nlpar="kr"),
prior(lkj(1), class="cor")
)
inits <- list(
c0 = 6.0,
kr= 0.6,
nt=0.92
)
list_of_inits <- list(inits, inits, inits, inits)
asc_multi_bayes <- brm(formula=nlform, data=asc70, family=gaussian(),
prior=nlprior, iter=20000, warmup=10000, seed=1234,
chains=4,
cores=4,
inits = list_of_inits,
control = list(adapt_delta=0.9999, max_treedepth=15), backend="cmdstanr",
file=here("fits","asc_multi_bayes"))
nlform<-bf(conc ~ (c0^(1-nt)+(nt-1)*kr*time)^(1/(1-nt)),
c0 ~1+(1|ID|run),
nt~1+(1|ID|run),
kr ~ 1+(1|ID|run),
nl=TRUE)
nlprior<-c(prior(normal(6.0,0.5), nlpar = "c0", lb=0),
prior(normal(0.5,0.1), nlpar="kr", lb=0),
prior(normal(1,0.1), nlpar="nt", lb=0),
prior(cauchy(0,1), class="sigma"),
prior(cauchy(0,1), class="sd", nlpar="c0"),
prior(cauchy(0,1), class="sd", nlpar="nt"),
prior(cauchy(0,1), class="sd", nlpar="kr"),
prior(lkj(1), class="cor")
)
inits <- list(
c0 = 6.0,
kr= 0.6,
nt=0.92
)
list_of_inits <- list(inits, inits, inits, inits)
asc_multi_bayes <- brm(formula=nlform, data=asc70, family=gaussian(),
prior=nlprior, iter=20000, warmup=10000, seed=1234,
chains=4,
cores=4,
inits = list_of_inits,
control = list(adapt_delta=0.9999, max_treedepth=15))
asc70
standata(asc_multi_bayes)
View(inits)
View(asc70)
ID
2*(3-2)^2/5-4
2*((3-2)^2/5)-4
2*((3+2)^2/5)-4
install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
devtools::install_github("rmcelreath/rethinking")
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty", "shape"))
install.packages(c("coda", "mvtnorm", "devtools", "loo", "dagitty", "shape"))
install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
devtools::install_github("rmcelreath/rethinking")
library(devtools)
install.packages("devtools")
library(devtools)
install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
devtools::install_github("rmcelreath/rethinking")
detach("package:usethis", unload = TRUE)
detach("package:utils", unload = TRUE)
detach("package:utils", unload = TRUE)
install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
install.packages(c("coda","mvtnorm","devtools","loo","dagitty","shape"))
devtools::install_github("rmcelreath/rethinking")
# we recommend running this is a fresh R session or restarting your current session
install.packages("cmdstanr", repos = c("https://mc-stan.org/r-packages/", getOption("repos")))
check_cmdstan_toolchain()
library(cmdstanr)
library(cmdstanr)
detach("package:cmdstanr", unload = TRUE)
library(cmdstanr)
library(lifecycle)
library(cmdstanr)
detach("package:lifecycle", unload = TRUE)
detach("package:cmdstanr", unload = TRUE)
library(cmdstanr)
install.packages("lifecycles)
install.packages("lifecycles)
install.packages("lifecycles")
library(cmdstanr)
library(lifecycle)
detach("package:lifecycle", unload = TRUE)
library(lifecycle)
library(rstan)
sessionInfo()
library(cmdstanr)
library(cmdstanr)
install_cmdstan()
install.packages(rethinking)
devtools::install_github("rmcelreath/rethinking")
data(chimoanzees)
data(chimpanzees)
library(rethinking)
data(chimpanzees)
d chimpanzees
d <- chimpanzees
d$treatment <- 1 + d$prosoc_left + 2*d$condition
dat <- list(P = d$pulled_left,
A = d$actor,
B= d$block,
T = d$treatment)
dat <- list(P = d$pulled_left,
A = d$actor,
B= d$block,
T = d$treatment)
stancode(ulam(alist( P ~ bernoulli( p ),
logit(p) <- b[T,B] + a[A],
matrix[T,B]:b ~ dnorm(0 , sigma_B),
a[A] ~ dnorm(a_bar , sigma_A)
a_bar ~ dnorm(0 , 1.5)
m <- ulam(alist( P ~ bernoulli( p ),
logit(p) <- b[T,B] + a[A],
matrix[T,B]:b ~ dnorm(0 , sigma_B),
a[A] ~ dnorm(a_bar , sigma_A)
a_bar ~ dnorm(0 , 1.5)
m <- ulam(alist( P ~ bernoulli( p ),
logit(p) <- b[T,B] + a[A],
matrix[T,B]:b ~ dnorm(0 , sigma_B),
a[A] ~ dnorm(a_bar , sigma_A),
a_bar ~ dnorm(0 , 1.5),
sigma_A ~ dexp(1),
sigma_B ~ dexp(1)
),data = dat, chains = 4, cores = 4)
stancode(m)
m <- ulam(alist( P ~ bernoulli( p ),
logit(p) <- b[T,B] + a[A],
matrix[T,B]:b ~ dnorm(0 , sigma_B),
a[A] ~ dnorm(a_bar , sigma_A),
a_bar ~ dnorm(0 , 1.5),
sigma_A ~ dexp(1),
sigma_B ~ dexp(1)
), data = dat, chains = 4, cores = 4, cmdstan = TRUE)
m
summary(m)
m <- ulam(alist( P ~ bernoulli( p ),
logit(p) <- b[T,B] + a[A],
matrix[T,B]:b ~ dnorm(0 , sigma_B),
a[A] ~ dnorm(a_bar , sigma_A),
a_bar ~ dnorm(0 , 1.5),
sigma_A ~ dexp(1),
sigma_B ~ dexp(1)
), data = dat, chains = 4, cores = 4, cmdstan = TRUE, iter=2000; warmup=1000)
m <- ulam(alist( P ~ bernoulli( p ),
logit(p) <- b[T,B] + a[A],
matrix[T,B]:b ~ dnorm(0 , sigma_B),
a[A] ~ dnorm(a_bar , sigma_A),
a_bar ~ dnorm(0 , 1.5),
sigma_A ~ dexp(1),
sigma_B ~ dexp(1)
), data = dat, chains = 4, cores = 4, iter = 2000,cmdstan = TRUE)
summary(m)
m <- ulam(alist( P ~ bernoulli( p ),
logit(p) <- b[T,B] + a[A],
matrix[T,B]:b ~ dnorm(0 , sigma_B),
a[A] ~ dnorm(a_bar , sigma_A),
a_bar ~ dnorm(0 , 1.5),
sigma_A ~ dexp(1),
sigma_B ~ dexp(1)
), data = dat, chains = 4, cores = 4, iter = 1000,cmdstan = TRUE)
summary(m)
m <- ulam(alist( P ~ bernoulli( p ),
logit(p) <- b[T,B] + a[A],
matrix[T,B]:b ~ dnorm(0 , sigma_B),
a[A] ~ dnorm(a_bar , sigma_A),
a_bar ~ dnorm(0 , 1.5),
sigma_A ~ dexp(1),
sigma_B ~ dexp(1)
), data = dat, chains = 4, cores = 4, iter = 1000, warmup = 1000, cmdstan = TRUE)
summary(m)
stancode(m)
d$pulled_left
1:504
vector(1:504)
file <- """
data{
int P[504];
int A[504];
int B[504];
int T[504];
int<lower = 1, upper=504> id[504]
}
parameters{
matrix[4,6] b;
vector[7] a;
real a_bar;
real<lower=0> sigma_A;
real<lower=0> sigma_B;
}
model{
vector[504] p;
sigma_B ~ exponential( 1 );
sigma_A ~ exponential( 1 );
a_bar ~ normal( 0 , 1.5 );
a ~ normal( a_bar , sigma_A );
to_vector( b ) ~ normal( 0 , sigma_B );
p = b[T[id], B[id]] + a[A[id]];
p = inv_logit(p[id]);
P ~ bernoulli( p );
}
"""
file <- "
data{
int P[504];
int A[504];
int B[504];
int T[504];
int<lower = 1, upper=504> id[504]
}
parameters{
matrix[4,6] b;
vector[7] a;
real a_bar;
real<lower=0> sigma_A;
real<lower=0> sigma_B;
}
model{
vector[504] p;
sigma_B ~ exponential( 1 );
sigma_A ~ exponential( 1 );
a_bar ~ normal( 0 , 1.5 );
a ~ normal( a_bar , sigma_A );
to_vector( b ) ~ normal( 0 , sigma_B );
p = b[T[id], B[id]] + a[A[id]];
p = inv_logit(p[id]);
P ~ bernoulli( p );
}
"
mod <- cmdstan_model(file)
file
mod <- cmdstan_model(file)
library(rstan)
library(rethinking)
detach("package:rethinking", unload = TRUE)
dat <- list(P = d$pulled_left,
A = d$actor,
B= d$block,
T = d$treatment,
id = 1:length(d))
View(dat)
dat$id
View(chimpanzees)
dat <- list(P = d$pulled_left,
A = d$actor,
B= d$block,
T = d$treatment,
id = 1:nrow(d))
View(dat)
stan(file = file, data = dat)
?stan
stan(model_code = file, data = dat)
file <- "
data{
int P[504];
int A[504];
int B[504];
int T[504];
int<lower = 1, upper=504> id[504];
}
parameters{
matrix[4,6] b;
vector[7] a;
real a_bar;
real<lower=0> sigma_A;
real<lower=0> sigma_B;
}
model{
vector[504] p;
sigma_B ~ exponential( 1 );
sigma_A ~ exponential( 1 );
a_bar ~ normal( 0 , 1.5 );
a ~ normal( a_bar , sigma_A );
to_vector( b ) ~ normal( 0 , sigma_B );
p = b[T[id], B[id]] + a[A[id]];
p = inv_logit(p[id]);
P ~ bernoulli( p );
}
"
mod <- cmdstan_model(file)
stan(model_code = file, data = dat)
stancode(m)
library(rethinking)
stancode(m)
library(brms)
data("BTdata", package = "MCMCglmm")
installed.packages(MCMCglmm)
installed.packages("MCMCglmm")
data("BTdata", package = "MCMCglmm")
installed.packages("MCMCglmm")
installed.packages(MCMCglmm)
install.packages(MCMCglmm)
install.packages('MCMCglmm')
data("BTdata", package = "MCMCglmm")
bform1 <-
bf(mvbind(tarsus, back) ~ (1|p|fosternest)) +
set_rescor(TRUE)
fit1 <- brm(bform1, data = BTdata, chains = 2, cores = 2)
stancode(fit1)
a_bar <- rnorm(0, 1.5, 1000)
sigma <- rexp(1000,1)
sigma
a_j <- rnorm(a_bar,sigma, 1000)
hist(a_j)
plot(a_j)
a_bar <- rnorm(0, 1.5, 1000)
a_bar <- rnorm(1000, 0, 1.5)
sigma <- rexp(1000,1)
a_j <- rnorm(a_bar,sigma, 1000)
plot(a_j)
hist(a_j)
density(a_j)
library(rethinking)
dens(a_j)
dens(a)
dens(a_bar)
cd
setwd('\Desktop/')
setwd('/Desktop/')
setwd('Desktop/')
setwd('Desktop/Ba')
setwd("~/Desktop/Bayesian_stats/Statistical-methods-for-research-workers-bayes-for-psychologists-and-neuroscientists/wip/Data")
load("/Users/harrisoncurtis/Downloads/emotion.rda")
ls(
)
setwd("~/Desktop/Bayesian_stats/Statistical-methods-for-research-workers-bayes-for-psychologists-and-neuroscientists/wip/Data")
write.csv(emotion)
write.csv("~/Desktop/Bayesian_stats/Statistical-methods-for-research-workers-bayes-for-psychologists-and-neuroscientists/wip/Data")
write.csv(emotion, "~/Desktop/Bayesian_stats/Statistical-methods-for-research-workers-bayes-for-psychologists-and-neuroscientists/wip/Data")
write.csv(emotion, "~/Desktop/Bayesian_stats/Statistical-methods-for-research-workers-bayes-for-psychologists-and-neuroscientists/wip/Data/emotion.csv")
read.csv(emotion)
read.csv('emotion'.csv)
read.csv('emotion.csv')
d = read.csv('emotion.csv')
q()
